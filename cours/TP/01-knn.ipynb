{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3520f4ff4b4f589",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# TP en Traitement Automatique du Langage Naturel : Classification des Sentiments sur des Critiques de Films\n",
    "\n",
    "## Objectif\n",
    "Développer un système de classification des sentiments en utilisant des critiques de films. Vous utiliserez l'ensemble de données IMDb et appliquerez un modèle **K-Nearest Neighbors (KNN)** pour classer les critiques en catégories positives ou négatives.\n",
    "\n",
    "---\n",
    "\n",
    "## Questions\n",
    "1. Comment la réduction du nombre de caractéristiques (`max_features`) influence-t-elle la performance du modèle ?\n",
    "2. Quel est l'impact du choix du **nombre de voisins** dans KNN sur les résultats ?\n",
    "3. Comparez les performances du modèle KNN avec un autre classificateur (par exemple, [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) ou [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)). Lequel fonctionne le mieux et pourquoi ?\n",
    "4. Le prétraitement améliore-t-il la classification ? Justifiez votre réponse avec des résultats expérimentaux.\n",
    "\n",
    "---\n",
    "\n",
    "## Ressources Utiles\n",
    "- [Ensemble de données IMDb](https://huggingface.co/datasets/imdb)\n",
    "- [Documentation Scikit-learn](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "id": "15ccbdee81a84e54",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-01-31T09:46:18.875953Z",
     "start_time": "2025-01-31T09:46:04.240322Z"
    }
   },
   "source": [
    "!pip install -q -U datasets scikit-learn"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9bf4b70f36e01ec2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-01-31T09:47:42.094317Z",
     "start_time": "2025-01-31T09:47:38.013231Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# On split plusieur fois le dataset afin de réduire le temps de calcule\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "dataset = dataset.train_test_split(stratify_by_column=\"label\", test_size=0.5, seed=42)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T09:47:45.213218Z",
     "start_time": "2025-01-31T09:47:45.206776Z"
    }
   },
   "cell_type": "code",
   "source": "dataset",
   "id": "e2de1ee9aa775312",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c771147747d7f0be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-01-31T09:48:16.481197Z",
     "start_time": "2025-01-31T09:48:16.443083Z"
    }
   },
   "source": [
    "set(dataset['train']['label'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3775e39bb47f4b99",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-01-31T09:54:48.113334Z",
     "start_time": "2025-01-31T09:54:39.035283Z"
    }
   },
   "source": [
    "# Constantes\n",
    "TFIDF_MAX_FEATURES = 10  # Nombre maximal de caractéristiques à extraire en mode TF-IDF\n",
    "KNN_NEIGHBORS = 3  # Nombre de voisins à considérer dans l'algorithme KNN\n",
    "\n",
    "def vectorize_text(train_texts, test_texts, max_features):\n",
    "    \"\"\"\n",
    "    Vectorise les textes d'entraînement et de test à l'aide de TF-IDF.\n",
    "    Chaque document est représenté par un vecteur de caractéristiques numériques.\n",
    "\n",
    "    Paramètres :\n",
    "    - train_texts (list): Liste des textes de l'ensemble d'entraînement.\n",
    "    - test_texts (list): Liste des textes de l'ensemble de test.\n",
    "    - max_features (int): Nombre maximal de caractéristiques considérées par le vectoriseur.\n",
    "\n",
    "    Retourne :\n",
    "    - X_train (sparse matrix): Matrice de caractéristiques pour les données d'entraînement.\n",
    "    - X_test (sparse matrix): Matrice de caractéristiques pour les données de test.\n",
    "    - vectorizer (TfidfVectorizer): Instance du vectoriseur TF-IDF entraînée pour réutilisation.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features)  # Initialisation du vectoriseur avec un seuil max de caractéristiques\n",
    "    X_train = vectorizer.fit_transform(train_texts)  # Calcul et transformation des textes d'entraînement\n",
    "    X_test = vectorizer.transform(test_texts)  # Transformation des textes de test avec le même vectoriseur\n",
    "    return X_train, X_test, vectorizer\n",
    "\n",
    "\n",
    "def train_and_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors):\n",
    "    \"\"\"\n",
    "    Entraîne et évalue un modèle KNN pour la classification des textes.\n",
    "\n",
    "    Paramètres :\n",
    "    - X_train (sparse matrix): Matrice des caractéristiques pour l'entraînement.\n",
    "    - y_train (array): Étiquettes associées aux données d'entraînement.\n",
    "    - X_test (sparse matrix): Matrice des caractéristiques pour les données de test.\n",
    "    - y_test (array): Étiquettes associées aux données de test.\n",
    "    - n_neighbors (int): Nombre de voisins pris en compte dans l'algorithme KNN.\n",
    "\n",
    "    Comportement :\n",
    "    - Entraîne le modèle sur les données d'entraînement.\n",
    "    - Effectue des prédictions sur les données de test.\n",
    "    - Affiche un rapport de classification basé sur les prédictions.\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(\n",
    "            n_neighbors=n_neighbors)  # Initialisation du classificateur KNN avec un certain nombre de voisins\n",
    "    knn.fit(X_train, y_train)  # Entraînement du modèle sur les données d'entrée\n",
    "    y_pred = knn.predict(X_test)  # Prédictions sur les données de test\n",
    "    print(classification_report(y_test, y_pred))  # Affichage des métriques de classification (précision, rappel, etc.)\n",
    "\n",
    "\n",
    "# Flux principal du script\n",
    "# Vectorisation des textes d'entraînement et de test\n",
    "X_train, X_test, vectorizer = vectorize_text(dataset['train']['text'], dataset['test']['text'], TFIDF_MAX_FEATURES)\n",
    "\n",
    "# Séparation des étiquettes pour les ensembles d'entraînement et de test\n",
    "y_train, y_test = dataset['train']['label'], dataset['test']['label']\n",
    "\n",
    "# Formation et évaluation du modèle KNN avec les données vectorisées\n",
    "train_and_evaluate_knn(X_train, y_train, X_test, y_test, KNN_NEIGHBORS)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.55      6250\n",
      "           1       0.55      0.54      0.54      6250\n",
      "\n",
      "    accuracy                           0.55     12500\n",
      "   macro avg       0.55      0.55      0.55     12500\n",
      "weighted avg       0.55      0.55      0.55     12500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
