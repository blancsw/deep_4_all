{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TP en Traitement Automatique du Langage Naturel: Classification de Sentiments sur des Critiques de Films\n",
    "\n",
    "## Objectif\n",
    "L'objectif de ce TP est de développer un système de classification de sentiments utilisant des critiques de films. Vous utiliserez un ensemble de données IMDb et appliqueront un modèle K-Nearest Neighbors (KNN) pour classer les critiques en catégories positives ou négatives.\n",
    "\n",
    "## Partie 1: Traitement des Textes\n",
    "1. **Preprocess**: Appliquer un preprocess si besoin\n",
    "1. **Vectorisation**: Transformez les documents textuels en vecteurs numériques en utilisant `TfidfVectorizer`.\n",
    "\n",
    "## Partie 3: Modélisation\n",
    "1. **Construction du Modèle KNN**: Créez un modèle KNN\n",
    "2. **Entraînement du Modèle**: Entraînez le modèle sur l'ensemble d'entraînement.\n",
    "\n",
    "## Partie 4: Évaluation\n",
    "1. **Prédiction et Classification**: Utilisez le modèle pour prédire les sentiments sur l'ensemble de test.\n",
    "2. **Rapport de Classification**: Générez un rapport de classification pour évaluer la performance du modèle.\n",
    "\n",
    "## Questions\n",
    "1. Comment la réduction du nombre de caractéristiques (`max_features`) affecte-t-elle la performance du modèle ?\n",
    "2. Quel impact a le choix du nombre de voisins dans KNN sur les résultats ?\n",
    "3. Comparez les performances du modèle KNN avec un autre classificateur (par exemple, Naive Bayes ou SVM). Lequel performe mieux et pourquoi ?\n",
    "4. Le preprocessing améliore t-il la claasification ?\n",
    "\n",
    "## Ressources\n",
    "- [IMDb Dataset](https://huggingface.co/datasets/imdb)\n",
    "- [Scikit-learn Documentation](https://scikit-learn.org/stable/)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3520f4ff4b4f589"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# On split plusieur fois le dataset afin de réduire le temps de calcule\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "dataset = dataset.train_test_split(stratify_by_column=\"label\", test_size=0.3, seed=42)\n",
    "dataset = dataset['train'].train_test_split(stratify_by_column=\"label\", test_size=0.3, seed=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf4b70f36e01ec2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Solution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "729457e7704fe9cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Prepare train, test dataset\n",
    "train_docs, y_train = dataset['train']['text'], dataset['train']['label']\n",
    "test_docs, y_test = dataset['test']['text'], dataset['test']['label']\n",
    "\n",
    "# Vectorization of text documents\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_docs)\n",
    "X_test = vectorizer.transform(test_docs)\n",
    "\n",
    "# KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdf8c58c1ea6bb8",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
