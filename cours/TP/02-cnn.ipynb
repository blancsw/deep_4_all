{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Travail Pratique: Création d'un Modèle GoogLeNet Miniature\n",
    "\n",
    "## GoogLeNet: Un Aperçu Historique\n",
    "GoogLeNet est un modèle de réseau neuronal convolutif profond qui a été proposé par des chercheurs de Google, d'où son nom. Le modèle a été introduit pour la première fois en 2014 dans le papier de recherche intitulé \"[Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)\", et a remporté le défi de la classification visuelle d'ImageNet (ILSVRC) cette même année.\n",
    "Le modèle est plus particulièrement célèbre pour deux de ses caractéristiques uniques :\n",
    "\n",
    "\n",
    "\n",
    "### Inception Module :\n",
    "L'Inception Module est une micro-architecture novatrice (ou un \"bloc de construction\") pour les CNN. Il est basé sur une philosophie intelligente de conception de réseau qui interroge \"à quoi ressemblerait une bonne solution locale\" pour la conception de réseau.\n",
    "\n",
    "Le Module Inception a introduit l'idée d'avoir plusieurs opérations de convolution de différentes tailles (1x1, 3x3, 5x5) en parallèle dans un même niveau de l'architecture, permettant au CNN d'apprendre des caractéristiques à différentes échelles. Cela a également amené à une plus grande efficacité en termes de calcul.\n",
    "\n",
    "![inception](../asset/inception.png)\n",
    "\n",
    "### Profondeur du réseau :\n",
    "GoogLeNet a été l'un des premiers réseaux neuronaux profonds avec 22 couches de profondeur. En utilisant l'Inception Module et une grande profondeur, GoogLeNet a pu atteindre des performances élevées sur diverses tâches de vision par ordinateur, y compris la classification des images.\n",
    "Il convient de noter que même si GoogLeNet a lancé l'idée originale du Module Inception, de nombreuses variantes et améliorations ont été introduites depuis, telles que Inception-v2, Inception-v3 et Inception-v4, chacune améliorant les performances et l'efficacité de la précédente.\n",
    "\n",
    "![googlenet architecture](../asset/googlenet_architecture.png)\n",
    "\n",
    "Pour l'anecdote, ce modèle compte 25 millions de paramètres, en 2014 il était assser difficile pour l'utilisateur classique de le train  Maintenant, un LLM classique comme Mistral comporte 7 milliards de paramètres, ou comme ChatGPT-3.5 qui en compte 175 milliards !!!\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Au cours de ce TP, nous allons apprendre à utiliser les Réseaux de neurones à convolution (CNN) pour construire un modèle miniature GoogLeNet avec l'Inception Module. L'algorithme sera utilisé pour le torchvision.datasets.CIFAR10 dataset.\n",
    "\n",
    "Nous alons réaliser une version minature de celui-ci\n",
    "\n",
    "![GoogleNet](../asset/mini_googlenet.png)\n",
    "\n",
    "L'architecture MiniGoogLeNet se compose de blocs de construction incluant un module de convolution, un module Inception et un module de sous-échantillonnage (downsample). Ces modules sont assemblés pour former l'architecture globale.\n",
    "\n",
    "\n",
    "**Note** 32 + 32 filters veux dire 32 filtre en 1X1 et 32 filtres en 3x3\n",
    "\n",
    "![note_filters](../asset/note_inception.png)\n",
    "\n",
    "## Ressources\n",
    "\n",
    "- [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)\n",
    "- [Torch conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3520f4ff4b4f589"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install -q -U scikit-learn torch torchvision matplotlib"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15ccbdee81a84e54",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Préparation des Données\n",
    "Téléchargez et préparez votre jeu de données CIFAR10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2466f77d188db002"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf4b70f36e01ec2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "\n",
    "# Batch, color chan, width, height\n",
    "print(\"Shape\", images.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5caeec0e2cb4e77c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def convolution_module(in_channels, out_channels, kernel_size, stride=1, padding=\"same\"):\n",
    "    return nn.Sequential()\n",
    "\n",
    "\n",
    "class MiniInception(nn.Module):\n",
    "    def __init__(self, in_channels, n1x1, n3x3):\n",
    "        super(MiniInception, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([], dim=1)\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels, n3x3):\n",
    "        super(Downsample, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Produce 2*n3x3 filters with the cat\n",
    "        return torch.cat([], dim=1)\n",
    "\n",
    "\n",
    "class MiniGoogLeNet(nn.Module):\n",
    "    def __init__(self, in_channels, classes):\n",
    "        super(MiniGoogLeNet, self).__init__()\n",
    "\n",
    "        self.mini_googlenet = nn.Sequential(\n",
    "            convolution_module(in_channels, 96, kernel_size=3)\n",
    "        )\n",
    "\n",
    "\n",
    "cnn = MiniGoogLeNet(3, 10)\n",
    "\n",
    "cnn.mini_googlenet(images[:1]).shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8beabc57d679abec",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
