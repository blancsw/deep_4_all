{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA (Low-Rank Adaptation) - Adaptation par Mise à Jour de Rang Faible\n",
    "\n",
    "Dans ce notebook, nous allons présenter le concept de **LoRA** et l'illustrer avec un exemple simple en PyTorch.\n",
    "\n",
    "L'idée de LoRA est de **ne pas mettre à jour l'ensemble des paramètres** d'un modèle pré-entraîné, mais d'ajouter une **mise à jour de rang faible** à certaines matrices de poids. Pour une matrice de poids \\(W\\), on introduit une mise à jour de la forme :\n",
    "\n",
    "$$\n",
    "\\Delta W = A \\times B,\n",
    "$$\n",
    "\n",
    "La matrice finale utilisée lors de l'inférence devient alors :\n",
    "\n",
    "$$\n",
    "W_{\\text{adapté}} = W + A \\times B.\n",
    "$$\n",
    "\n",
    "On entraîne uniquement les matrices \\(A\\) et \\(B\\) (de petit rang), ce qui permet de réduire le nombre de paramètres entraînables et donc les ressources nécessaires pour l'adaptation."
   ],
   "id": "db5aaed10bcb8936"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, r=4):\n",
    "        \"\"\"\n",
    "        in_features  : dimension de l'entrée\n",
    "        out_features : dimension de la sortie\n",
    "        r            : rang de la décomposition (nombre de colonnes de A et lignes de B)\n",
    "        \"\"\"\n",
    "        super(LoRALinear, self).__init__()\n",
    "        \n",
    "        # Poids pré-entraîné (fixé, non entraînable)\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features), requires_grad=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features), requires_grad=False)\n",
    "        \n",
    "        # Paramètres de la mise à jour de rang faible (seuls ces paramètres seront entraînés)\n",
    "        self.A = nn.Parameter(torch.randn(out_features, r))\n",
    "        self.B = nn.Parameter(torch.randn(r, in_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Calcul de la mise à jour de rang faible\n",
    "        delta_W = self.A @ self.B  # Produit matriciel de A et B\n",
    "        # Calcul de la sortie avec le poids mis à jour\n",
    "        W_updated = self.weight + delta_W\n",
    "        return x @ W_updated.t() + self.bias\n",
    "\n",
    "# Vérification de la définition de la classe\n",
    "print(LoRALinear)"
   ],
   "id": "ad2efc7a3fc894ed"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un Jeu de Données Synthétique et Entraînement\n",
    "\n",
    "Nous allons générer un jeu de données synthétique pour illustrer l'entraînement d'un modèle utilisant LoRA. La relation entre les entrées et les sorties sera linéaire, de la forme :\n",
    "\n",
    "$$\n",
    "y = x \\times W_{true}^T + b_{true},\n",
    "$$\n",
    "\n",
    "Lors de l'entraînement, nous n'ajusterons que les matrices \\(A\\) et \\(B\\) afin d'adapter la couche à la tâche."
   ],
   "id": "c780b61ea0238fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres du modèle et génération des données\n",
    "torch.manual_seed(42)\n",
    "in_features = 10\n",
    "out_features = 2\n",
    "r = 2  # Rang faible\n",
    "\n",
    "# Instanciation du modèle LoRA\n",
    "model = LoRALinear(in_features, out_features, r)\n",
    "\n",
    "# Génération de données synthétiques : y = x @ W_true.T + b_true\n",
    "N = 100  # Nombre d'exemples\n",
    "x = torch.randn(N, in_features)\n",
    "W_true = torch.randn(out_features, in_features)\n",
    "b_true = torch.randn(out_features)\n",
    "y = x @ W_true.t() + b_true\n",
    "\n",
    "# Définition de la fonction de perte et de l'optimiseur\n",
    "# Seuls les paramètres A et B sont entraînés\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD([model.A, model.B], lr=0.01)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ],
   "id": "a1a61da1301adf5c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Nous avons ainsi illustré comment le concept de **LoRA** permet d'adapter un modèle pré-entraîné en n'ajustant que quelques paramètres (les matrices \\(A\\) et \\(B\\)). Cette approche est particulièrement intéressante pour réduire le coût en ressources et mémoire lors du fine-tuning sur de nouvelles tâches, tout en conservant les paramètres d'origine du modèle."
   ],
   "id": "238d0c955330125d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
